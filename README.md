# Numerical-Optimization-Technique
Applying Machine learning Gradient Descent Optimizers like(Batch - Mini Batch - Stochastic - Momentum based - Nestrove accelerated - Adagrad - Rmsprop - Adam - Adam with mini batch for multivariable) from Scratch
